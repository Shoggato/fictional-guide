<!DOCTYPE html>
<html>
<head>
    <title>2023 DataScience Bootcamp <br> Washington University</title>
</head>
<body>
    <h1>Module 3</h1><br>
    <p><strong>Overview</strong><br> This week, you will transition from VBA to programming with Python. 
        First, you’ll learn about the basics of the command-line interface, or CLI, which is used to work with the files and folders on your computer. 
        Although it will take some time to get used to, the command line, also called the terminal, can be faster and more effective than your operating system's graphical user interface (GUI). 
        You'll get plenty of exposure to the command line throughout the course.</p><br>
    <p> Once you’ve explored the command line, you’ll install Python and begin to explore some basic functionality like variables, conditionals, and loops. 
        Next, you will turn your attention to learning how to read from and write to CSV files with Python. 
        Finally, you’ll expand your Python knowledge by using dictionaries and lists. 
        There’s a lot to cover, so let’s get started!</p><br>
    <h2>Table of Contents:</h2>    
    <a href="3.1 -Introduction to Python">Go to 3.1</a><br>
    <a href="3.2 -Reading and Writing in Python">Go to 3.2</a><br>
    <a href="3.3 -A Deeper Dive into Python">Go to 3.3</a><br>
    
    <h1>Module 4</h1><br>
    <h2>Introduction to Pandas</h2><br>
    <p><strong>Overview</strong><br>  In this module, you'll be introduced to Anaconda, an open-source distribution software, and one of its products, Jupyter Notebook. 
        Jupyter Notebook allows you to create documents that contain live code by using Python. 
        It supports over 40 different programming languages, but for this module, you'll learn the basics of the Pandas library.</p><br>
        <p>Pandas is an open-source library that provides high-performance data analysis tools. 
        Using Jupyter Notebook and the Pandas library, you'll read raw data from CSV files, inspect and clean data, merge datasets,
        perform mathematical calculations, and visualize the data with charts and graphs to tell a story.</p><br>
    <h2>Table of Contents:</h2>
    <a href="4.1 -Introduction To Pandas And Jupyter">Go to 4.1</a><br>
    <a href="4.2 -Exploring Pandas">Go to 4.2</a><br>
    <a href="4.3 -Merging And Data Cleaning">Go to 4.3</a><br>
    
    <h1>Module 5</h1><br>
    <p><strong>Data Visualizatoin</strong><br>In this module, you'll learn how to graph data by using the Matplotlib library. Matplotlib has a rich set of features for creating and annotating charts that visualize data in a Series or DataFrame. 
        You will use Matplotlib to create line charts, bar charts, scatter plots, pie charts, and box-and-whisker plots. 
        And, you’ll make your charts more informative by adding titles, axes labels, legends, and custom colors.<br>
        You'll also be introduced to SciPy, a statistical Python package, and NumPy, a fundamental package for scientific computing in Python. Using Pandas, SciPy, and NumPy, you’ll calculate summary statistics.<br>
        This module covers a lot of territory: you’ll build a variety of charts, leverage your knowledge of Python arrays and tuples, and apply Pandas methods, functions, and conditional expressions. 
        You will also perform mathematical calculations on Series and DataFrames.</p><br>
    <h2>Table of Contents:</h2>
    <a href="5.1 -Introduction to Matplotlib">Go to 5.1</a><br>
    <a href="5.2 -Plotting with Pandas">Go to 5.2</a><br>
    <a href="5.3 -Introduction to Statistics">Go to 5.3</a><br>

    <h1>Module 6</h1><br>
    <p><strong>Python APIs</strong><br> With the help of the Pandas library, you can now perform quantitative analysis and create compelling data visualizations. 
        However, you will need special tools to programmatically obtain and parse real-world data.<br> 
        That’s where APIs come in. <br>
        An application programming interface (API) is a set of functions that applications use to automate the back-and-forth communication between computers.<br></p>
        <p>This week, you will use APIs to obtain and parse data from sources such as OpenWeatherMap, the U.S. Census, OMDb, and more. 
        You will also have an opportunity to test your skills by plotting DataFrames from the API data by using Matplotlib.</p><br>
    <h2>Table of Contents:</h2>
    <a href="6.1 -APIs">Go to 6.1</a><br>
    <a href="6.2 -Working With Weather And City APIs">Go to 6.2</a><br>
    <a href="6.3 -APIs And Geospatial Data Visulization">Go to 6.3</a><br>

    <h1>Module 7</h1><br>
    <h2>Project 1 Week 1</h2>
    

    <h1>Module 8</h1><br>
    <h2>Project 1 Week 2</h2>
    

    <h1>Module 9</h1><br>
    <p><strong>SQL</strong><br>In this module, you'll learn how to do data modeling, engineering, and analysis by using Structured Query Language (SQL). 
        Applying your knowledge of DataFrames and tabular data, you'll create entity relationship diagrams (ERDs), import data into a database, troubleshoot common errors, and create queries that use data to answer questions. 
        Databases are used everywhere—in small and large businesses and even by individuals working on personal projects. And, SQL is one of the most widely used database query languages. 
        Its ability to organize and query data, especially on a large scale, makes SQL knowledge a skill that’s highly sought after in the workforce.</p><br>
    <a href="9.1 -Introduction To SQL">Go to 9.1</a><br>
    <a href="9.2 -Advanced SQL Queries">Go to 9.2</a><br>
    <a href="9.3 -Data Modeling">Go to 9.3</a><br>

    <h1>Module 10</h1><br>
    <p><strong>Advanced Data Storage and Retrieval</strong><br>In this module, you'll receive an introduction to three new tools: SQLite, SQLAlchemy, and Flask. 
        You’ll use these tools to build on your knowledge of SQL database structures and querying methods. 
        You'll also write and run Python code in a Jupyter notebook and create graphs by using Python.</p><br>
    <p>Table of Contents:</p>
    <a href="10.1 -Introduction to SQLAlchemy">Go to 10.1</a><br>
    <a href="10.2 -Advanced Usage of the SQLAlchemy ORM">Go to 10.2</a><br>
    <a href="10.3 -Introduction to Flask and Serving Data with APIs">Go to 10.3</a><br>

    <h1>Module 11</h1><br>
    <p><strong>Data Collection</strong><br>This week will focus on collecting data from websites via web scraping techniques. First, you'll learn about how websites are made by using HTML and CSS. 
        You will build your own simple websites to make sure that you understand how HTML and CSS work together to design the content and style of web pages. 
        Then, you'll use your knowledge of HTML and CSS, alongside the Python package Beautiful Soup, to extract specific information from HTML code.</p><br>
    <p>Once you have developed your web scraping skills, you'll take them even further by scraping real websites. You'll use the automated browsing package Splinter to extract and store data from multiple pages of the same website. 
        There’s a lot to cover, so let’s get started!</p>
    <h2>Table of Contents:</h2><br>
    <a href="11.1 -Scraping HTML">Go to 11.1</a><br>
    <a href="11.2 -Web Scraping with CSS Selectors">Go to 11.2</a><br>
    <a href="11.3 -Automated Browsing">Go to 11.3</a><br>

    <h1>Module 12</h1><br>
    <p><strong>NoSQL Databases</strong><br>In this module, you'll be introduced to the concept of the NoSQL database with MongoDB, the leading database management system for this language. 
        You will then expand on your data skills to work with non-relational documents, utilizing the PyMongo library to interface with your Mongo databases using Python. 
        Finally, you'll learn how to build aggregation pipelines when retrieving data, and integrate skills you have learned in previous classes, such as Pandas, APIs, and Matplotlib.</p><br>
    <h2>Table of Contents:</h2><br>
    <a href="12.1 -Introduction to NoSQL and MongoDB">Go to 12.1</a><br>
    <a href="12.2 -PyMongo and Advanced Queries">Go to 12.2</a><br>
    <a href="12.3 -Aggregation, Analysis, and Integration with MongoDB">Go to 12.3</a><br>

    <h1>Module 13</h1><br>
    <h2>Project 2 Week 1</h2><br>
    <h2>Table of Contents:</h2><br>
    <a href="13.1 -Extract, Transform, and Load">Go to 13.1</a><br>
    <a href="13.2 -Transformation and Cleaning with Regular Expressions and ETL Project Work">Go to 13.2</a><br>
    <a href="13.3 -ETL Project Work and helpful links">Go to 13.3</a><br>

    <h1>Module 14</h1><br>
    <p><strong>Interactive Visualizations</strong><br>In this module, you will use Plotly, a JavaScript data visualization library, to create data visualizations that are attractive, accessible, and interactive. 
        Libraries like Plotly offer interactivity, which can help your audience better understand your data and draw the same conclusions that you did. Later, you’ll use JavaScript to enhance the interactive features of your visualizations by building out buttons and dropdown menus. 
        You’ll also build on your JavaScript foundation to manipulate, parse, transform, and retrieve data from external sources like .csv files and APIs. 
        Finally, you’ll deploy a polished data visualization to the web, all using the power of JavaScript.</p><br>
    <h2>Table of Contents:</h2><br>
    <a href="14.1 -Introduction to JavaScript Visualizations">Go to 14.1</a><br>
    <a href="14.2 -Functional Programing for Data Processing">Go to 14.2</a><br>
    <a href="14.3 -JavaScript with D3.js">Go to 14.3</a><br>

    <h1>Module 15</h1><br>
    <p><strong>Advanced Interactive Visualizations Using JavaScript</strong><br>Creating effective, interactive maps is a critical skill for anyone in the data field. Used across a wide variety of applications and fields, maps allow us to explore, understand and make decisions about our world. 
        In this module, you’ll build on your JavaScript skills and the D3 library to create interactive maps.
        You’ll use GeoJSON, a type of JSON file specifically designed to host geographical information, to develop points, linestrings, and polygons. 
        You’ll also explore <strong>non-spatial attributes</strong>, or data that is independent of all geometric considerations, and packaged in the hierarchical structure of GeoJSON files.</p><br>
    <h2>Table of Contents:</h2>
    <a href="15.1 -Data Visualization with Leaflet">Go to 15.1</a><br>
    <a href="15.2 -GeoJSON and Leaflet Plugins">Go to 15.2</a><br>
    <a href="15.3 -Citi Bike Project with Leaflet and Intro to Projects">Go to 15.3</a><br>

    <h1>Module 16</h1><br>
    <h2>Project 3 Week 1</h2>
    <p><strong>Data Ethics</strong><br>This week will focus on some of the legal and ethical issues that come with using data. First, you'll learn about legal protections regarding the usage of data, such as copyright protections and licensing. 
        Then, you'll learn about some common ethical considerations around using data, such as privacy concerns and issues related to who is included or excluded from a dataset.</p><br>
    <p>Next, you will learn about algorithmic bias and study some examples of when algorithmic bias has occurred. 
        Finally, you will learn about different ways that data and privacy are regulated, studying laws such as the General Data Protection Regulation (GDPR) and the Family Educational Rights and Privacy Act (FERPA), to name just two. 
        In addition to exploring the interesting and complex world of data ethics and laws, you will continue to work with your team to complete Project 3. 
        There’s a lot to cover, so let’s get started!</p><br>
    <h2>Table of Contents:</h2>
    <a href="16.1 -Introduction to Data Ethis">Go to 16.1</a><br>
    <a href="16.2 -Legal and Ethical Issues">Go to 16.2</a><br>
    <a href="16.3 -Laws and Regulations for Privacy">Go to 16.3</a><br>


</body>
</html>
